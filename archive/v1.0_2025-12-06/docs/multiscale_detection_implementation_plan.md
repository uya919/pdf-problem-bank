# ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ë¸”ë¡ ê²€ì¶œ êµ¬í˜„ ê³„íš

**ëª©í‘œ**: ì‚¬ëŒ ëˆˆìœ¼ë¡œ ë´¤ì„ ë•Œ ì¡´ì¬í•˜ëŠ” **ëª¨ë“ ** ë¸”ë¡ì„ ë¹ ì§ì—†ì´ ê²€ì¶œ
**ë°©ë²•ë¡ **: Multi-scale Morphological Analysis
**ì‘ì„±ì¼**: 2025-11-16
**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 4-5ì‹œê°„ (êµ¬í˜„ + í…ŒìŠ¤íŠ¸)

---

## ğŸ“‹ ì „ì²´ ê°œìš”

### í•µì‹¬ ì›ë¦¬

**"ëª¨ë“  í¬ê¸°ì˜ ë¸”ë¡ì„ ê²€ì¶œí•˜ë ¤ë©´, ëª¨ë“  ìŠ¤ì¼€ì¼ì—ì„œ ê²€ì¶œí•´ì•¼ í•œë‹¤"**

```
í° ìŠ¤ì¼€ì¼ (h_kernel=15):
  [ë¬¸ì œ 01 ì „ì²´ ì œëª©ê³¼ ì§€ë¬¸ì´ í•˜ë‚˜ë¡œ]
  â†’ í° êµ¬ì¡° íŒŒì•…

ì¤‘ê°„ ìŠ¤ì¼€ì¼ (h_kernel=10):
  [ë¬¸ì œ 01] [ì œëª©] [ì§€ë¬¸ ë¼ì¸1] [ì§€ë¬¸ ë¼ì¸2]
  â†’ ì˜ë¯¸ ë‹¨ìœ„

ì‘ì€ ìŠ¤ì¼€ì¼ (h_kernel=7):
  [ë¬¸] [ì œ] [01] [ì œëª©] [ì§€ë¬¸] [ë¼ì¸1] [ë‹¨ì–´1] [ë‹¨ì–´2]
  â†’ ì„¸ë¶€ ìš”ì†Œ

ì´ˆì†Œí˜• ìŠ¤ì¼€ì¼ (h_kernel=5):
  [ë¬¸][ì œ][0][1][ì œ][ëª©][ì§€][ë¬¸][ë¼][ì¸]...
  â†’ ê°œë³„ ìš”ì†Œ (ë„ˆë¬´ ì„¸ë°€, ì„ íƒì  ì‚¬ìš©)

ìµœì¢… ë³‘í•©:
  í° ìŠ¤ì¼€ì¼ì˜ ê²°ê³¼ + ì¤‘ê°„ ìŠ¤ì¼€ì¼ì˜ ì¶”ê°€ ë¸”ë¡ + ì‘ì€ ìŠ¤ì¼€ì¼ì˜ ì¶”ê°€ ë¸”ë¡
  = ëª¨ë“  ìŠ¤ì¼€ì¼ì˜ ë¸”ë¡ í¬í•¨
```

### ë³‘í•© ì „ëµ

**í•µì‹¬ ì•„ì´ë””ì–´**: "ê³„ì¸µì  í¬í•¨ ê´€ê³„ ìœ ì§€"

```python
# ì˜ˆì‹œ:
í° ë¸”ë¡: [0, 0, 100, 50]     (ì œëª© ì „ì²´)
ì‘ì€ ë¸”ë¡1: [0, 0, 30, 25]   (ë¬¸ì œ ë²ˆí˜¸)
ì‘ì€ ë¸”ë¡2: [35, 0, 100, 50] (ì œëª© í…ìŠ¤íŠ¸)

ë³‘í•© ê²°ê³¼:
â†’ 3ê°œ ë¸”ë¡ ëª¨ë‘ ìœ ì§€
â†’ í° ë¸”ë¡ì€ "ë¶€ëª¨ ë¸”ë¡" ì—­í• 
â†’ ì‘ì€ ë¸”ë¡ë“¤ì€ "ìì‹ ë¸”ë¡" ì—­í• 

ì´ìœ :
- ì‚¬ìš©ìê°€ "ì œëª© ì „ì²´"ë¥¼ ì„ íƒí•˜ê³  ì‹¶ì„ ë•Œ: í° ë¸”ë¡ ì‚¬ìš©
- ì‚¬ìš©ìê°€ "ë²ˆí˜¸ë§Œ" ì„ íƒí•˜ê³  ì‹¶ì„ ë•Œ: ì‘ì€ ë¸”ë¡1 ì‚¬ìš©
- ëª¨ë“  ê°€ëŠ¥ì„± ì œê³µ
```

---

## ğŸ—ï¸ Phase 1: ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1.1 ìƒˆë¡œìš´ í´ë˜ìŠ¤ êµ¬ì¡°

**multiscale_analyzer.py ìƒì„±**:

```python
class MultiscaleAnalyzer:
    """
    ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ë¸”ë¡ ê²€ì¶œê¸°

    ì—¬ëŸ¬ ì»¤ë„ í¬ê¸°ë¡œ ê²€ì¶œí•œ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬
    ëª¨ë“  í¬ê¸°ì˜ ë¸”ë¡ì„ ë¹ ì§ì—†ì´ ê²€ì¶œ
    """

    def __init__(self, config: Config):
        self.config = config
        self.density_analyzer = DensityAnalyzer(config)

        # ìŠ¤ì¼€ì¼ ì •ì˜
        self.scales = [
            {"name": "large", "h_kernel": 15, "v_kernel": 2},
            {"name": "medium", "h_kernel": 10, "v_kernel": 2},
            {"name": "small", "h_kernel": 7, "v_kernel": 2},
            {"name": "tiny", "h_kernel": 5, "v_kernel": 1},  # ì„ íƒì 
        ]

    def detect_all_blocks(
        self,
        image: np.ndarray,
        columns: List[Column],
        use_tiny: bool = False
    ) -> List[Block]:
        """
        ëª¨ë“  ìŠ¤ì¼€ì¼ì—ì„œ ë¸”ë¡ ê²€ì¶œ í›„ ë³‘í•©

        Args:
            image: í˜ì´ì§€ ì´ë¯¸ì§€
            columns: ì»¬ëŸ¼ ì •ë³´
            use_tiny: ì´ˆì†Œí˜• ìŠ¤ì¼€ì¼ ì‚¬ìš© ì—¬ë¶€

        Returns:
            ë³‘í•©ëœ ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
        """
        pass

    def _detect_at_scale(
        self,
        image: np.ndarray,
        columns: List[Column],
        h_kernel: int,
        v_kernel: int
    ) -> List[BoundingBox]:
        """íŠ¹ì • ìŠ¤ì¼€ì¼ì—ì„œ ë¸”ë¡ ê²€ì¶œ"""
        pass

    def _merge_blocks(
        self,
        blocks_by_scale: Dict[str, List[BoundingBox]]
    ) -> List[BoundingBox]:
        """
        ìŠ¤ì¼€ì¼ë³„ ë¸”ë¡ ë³‘í•©

        ì „ëµ:
        1. í° ìŠ¤ì¼€ì¼ë¶€í„° ì‹œì‘
        2. ì‘ì€ ìŠ¤ì¼€ì¼ì˜ ë¸”ë¡ ì¤‘ ìƒˆë¡œìš´ ê²ƒë§Œ ì¶”ê°€
        3. ì¤‘ë³µì€ ì œê±°í•˜ë˜, ê³„ì¸µ êµ¬ì¡°ëŠ” ìœ ì§€
        """
        pass

    def _is_duplicate(
        self,
        bbox1: BoundingBox,
        bbox2: BoundingBox,
        iou_threshold: float = 0.8
    ) -> bool:
        """ë‘ ë¸”ë¡ì´ ì¤‘ë³µì¸ì§€ íŒë‹¨ (IoU ê¸°ì¤€)"""
        pass

    def _is_contained(
        self,
        child: BoundingBox,
        parent: BoundingBox,
        threshold: float = 0.9
    ) -> bool:
        """childê°€ parentì— ê±°ì˜ í¬í•¨ë˜ëŠ”ì§€ íŒë‹¨"""
        pass
```

### 1.2 ë°ì´í„° ëª¨ë¸ í™•ì¥

**data_models.py ìˆ˜ì •**:

```python
@dataclass
class Block:
    """í…ìŠ¤íŠ¸ ë¸”ë¡"""
    block_id: int
    column: str
    bbox: BoundingBox
    pixel_density: float

    # ìƒˆë¡œìš´ í•„ë“œ ì¶”ê°€
    scale: str = "unknown"  # "large", "medium", "small", "tiny"
    parent_id: Optional[int] = None  # ë¶€ëª¨ ë¸”ë¡ ID (ê³„ì¸µ êµ¬ì¡°)
    children_ids: List[int] = field(default_factory=list)  # ìì‹ ë¸”ë¡ IDs

    def to_dict(self) -> dict:
        return {
            "block_id": int(self.block_id),
            "column": self.column,
            "bbox": self.bbox.to_list(),
            "pixel_density": float(self.pixel_density),
            "scale": self.scale,
            "parent_id": self.parent_id,
            "children_ids": self.children_ids
        }
```

---

## ğŸ”§ Phase 2: í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

### 2.1 ìŠ¤ì¼€ì¼ë³„ ê²€ì¶œ

**êµ¬í˜„ ì„¸ë¶€ì‚¬í•­**:

```python
def _detect_at_scale(
    self,
    image: np.ndarray,
    columns: List[Column],
    h_kernel: int,
    v_kernel: int
) -> List[BoundingBox]:
    """
    íŠ¹ì • ìŠ¤ì¼€ì¼ì—ì„œ ë¸”ë¡ ê²€ì¶œ

    í˜„ì¬ DensityAnalyzerë¥¼ ì¬ì‚¬ìš©í•˜ë˜,
    ì»¤ë„ í¬ê¸°ë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½
    """

    # 1. í°ìƒ‰ ë°°ê²½ ì œê±°
    mask = self._remove_white_background(image)

    # 2. ëª¨í´ë¡œì§€ ì—°ì‚°
    h_kernel_mat = cv2.getStructuringElement(
        cv2.MORPH_RECT, (h_kernel, 1)
    )
    h_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, h_kernel_mat)

    v_kernel_mat = cv2.getStructuringElement(
        cv2.MORPH_RECT, (1, v_kernel)
    )
    v_closed = cv2.morphologyEx(h_closed, cv2.MORPH_CLOSE, v_kernel_mat)

    # 3. ë…¸ì´ì¦ˆ ì œê±°
    final_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    mask_cleaned = cv2.morphologyEx(v_closed, cv2.MORPH_OPEN, final_kernel)

    # 4. ì»´í¬ë„ŒíŠ¸ ê²€ì¶œ
    contours, _ = cv2.findContours(
        mask_cleaned,
        cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE
    )

    # 5. BoundingBox ì¶”ì¶œ
    bboxes = []
    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)

        # ìµœì†Œ í¬ê¸° í•„í„° (ìŠ¤ì¼€ì¼ë³„ë¡œ ë‹¤ë¥´ê²Œ)
        min_size = self._get_min_size_for_scale(h_kernel)
        if w * h < min_size:
            continue

        bbox = BoundingBox(x, y, x + w, y + h)
        bboxes.append(bbox)

    return bboxes

def _get_min_size_for_scale(self, h_kernel: int) -> int:
    """
    ìŠ¤ì¼€ì¼ë³„ ìµœì†Œ ë¸”ë¡ í¬ê¸°

    ì‘ì€ ì»¤ë„ì¼ìˆ˜ë¡ ë” ì‘ì€ ë¸”ë¡ í—ˆìš©
    """
    if h_kernel >= 15:
        return 400  # í° ìŠ¤ì¼€ì¼: í° ë¸”ë¡ë§Œ
    elif h_kernel >= 10:
        return 300  # ì¤‘ê°„ ìŠ¤ì¼€ì¼
    elif h_kernel >= 7:
        return 200  # ì‘ì€ ìŠ¤ì¼€ì¼
    else:
        return 100  # ì´ˆì†Œí˜• ìŠ¤ì¼€ì¼: ë§¤ìš° ì‘ì€ ë¸”ë¡ë„ í—ˆìš©
```

### 2.2 ì¤‘ë³µ ì œê±° ì•Œê³ ë¦¬ì¦˜

**IoU (Intersection over Union) ê¸°ë°˜**:

```python
def _calculate_iou(
    self,
    bbox1: BoundingBox,
    bbox2: BoundingBox
) -> float:
    """
    ë‘ ë°•ìŠ¤ì˜ IoU ê³„ì‚°

    IoU = Intersection / Union
    """
    # êµì§‘í•© ì˜ì—­
    x_min = max(bbox1.x_min, bbox2.x_min)
    y_min = max(bbox1.y_min, bbox2.y_min)
    x_max = min(bbox1.x_max, bbox2.x_max)
    y_max = min(bbox1.y_max, bbox2.y_max)

    if x_max < x_min or y_max < y_min:
        return 0.0  # ê²¹ì¹˜ì§€ ì•ŠìŒ

    intersection = (x_max - x_min) * (y_max - y_min)

    # í•©ì§‘í•© ì˜ì—­
    area1 = bbox1.area
    area2 = bbox2.area
    union = area1 + area2 - intersection

    return intersection / union if union > 0 else 0.0

def _is_duplicate(
    self,
    bbox1: BoundingBox,
    bbox2: BoundingBox,
    iou_threshold: float = 0.85
) -> bool:
    """
    ë‘ ë¸”ë¡ì´ ì¤‘ë³µì¸ì§€ íŒë‹¨

    IoU > 0.85 â†’ ê±°ì˜ ê°™ì€ ë¸”ë¡ìœ¼ë¡œ íŒë‹¨
    """
    iou = self._calculate_iou(bbox1, bbox2)
    return iou > iou_threshold
```

### 2.3 ë³‘í•© ì „ëµ (í•µì‹¬!)

**ê³„ì¸µì  ë³‘í•©**:

```python
def _merge_blocks(
    self,
    blocks_by_scale: Dict[str, List[BoundingBox]]
) -> List[BoundingBox]:
    """
    ìŠ¤ì¼€ì¼ë³„ ë¸”ë¡ ë³‘í•©

    ì „ëµ:
    1. í° ìŠ¤ì¼€ì¼ â†’ ì‘ì€ ìŠ¤ì¼€ì¼ ìˆœìœ¼ë¡œ ì²˜ë¦¬
    2. ìƒˆë¡œìš´ ë¸”ë¡ë§Œ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
    3. í•˜ì§€ë§Œ ê³„ì¸µ êµ¬ì¡°ëŠ” ìœ ì§€

    ì˜ˆì‹œ:
    large: [A(ì „ì²´)]
    medium: [B(ì™¼ìª½), C(ì˜¤ë¥¸ìª½)]
    small: [D(ë²ˆí˜¸), E(í…ìŠ¤íŠ¸1), F(í…ìŠ¤íŠ¸2)]

    ê²°ê³¼: [A, B, C, D, E, F] (ëª¨ë‘ í¬í•¨)
    - AëŠ” B, Cë¥¼ í¬í•¨ â†’ parent
    - BëŠ” D, Eë¥¼ í¬í•¨ â†’ parent
    - D, E, FëŠ” leaf
    """

    merged = []

    # 1. í° ìŠ¤ì¼€ì¼ë¶€í„° ì¶”ê°€
    for scale_name in ["large", "medium", "small", "tiny"]:
        if scale_name not in blocks_by_scale:
            continue

        scale_blocks = blocks_by_scale[scale_name]

        for bbox in scale_blocks:
            # 2. ì´ë¯¸ ìˆëŠ” ë¸”ë¡ê³¼ ì¤‘ë³µ í™•ì¸
            is_new = True

            for existing in merged:
                iou = self._calculate_iou(bbox, existing)

                # 2-1. ê±°ì˜ ê°™ì€ ë¸”ë¡ (IoU > 0.85)
                if iou > 0.85:
                    is_new = False
                    break

                # 2-2. ê¸°ì¡´ ë¸”ë¡ì— ê±°ì˜ í¬í•¨ë¨ (IoU > 0.95, ë©´ì ë„ ì‘ìŒ)
                if iou > 0.95 and bbox.area < existing.area * 0.8:
                    # ì´ê±´ ìƒˆë¡œìš´ ë¸”ë¡ì´ì§€ë§Œ, ê¸°ì¡´ ë¸”ë¡ì˜ ì¼ë¶€
                    # â†’ ê³„ì¸µ ê´€ê³„ë¡œ ì²˜ë¦¬ (ë‚˜ì¤‘ì—)
                    pass

            # 3. ìƒˆë¡œìš´ ë¸”ë¡ì´ë©´ ì¶”ê°€
            if is_new:
                merged.append(bbox)

    return merged
```

**ê°œì„ ëœ ë³‘í•© (í¬í•¨ ê´€ê³„ ê³ ë ¤)**:

```python
def _merge_with_hierarchy(
    self,
    blocks_by_scale: Dict[str, List[BoundingBox]]
) -> List[BoundingBox]:
    """
    ê³„ì¸µ êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ë³‘í•©

    ì „ëµ:
    1. ëª¨ë“  ë¸”ë¡ì„ ì¼ë‹¨ ëª¨ìŒ
    2. í¬í•¨ ê´€ê³„ ë¶„ì„
    3. ì¤‘ë³µì€ ì œê±°, í¬í•¨ ê´€ê³„ëŠ” ìœ ì§€
    """

    all_blocks = []

    # 1. ëª¨ë“  ë¸”ë¡ ìˆ˜ì§‘ (ìŠ¤ì¼€ì¼ ì •ë³´ í¬í•¨)
    for scale_name in ["large", "medium", "small", "tiny"]:
        if scale_name not in blocks_by_scale:
            continue

        for bbox in blocks_by_scale[scale_name]:
            all_blocks.append({
                "bbox": bbox,
                "scale": scale_name,
                "area": bbox.area
            })

    # 2. ë©´ì  ê¸°ì¤€ ì •ë ¬ (í° ê²ƒë¶€í„°)
    all_blocks.sort(key=lambda x: x["area"], reverse=True)

    # 3. ì¤‘ë³µ ì œê±° ë° í¬í•¨ ê´€ê³„ ë¶„ì„
    unique_blocks = []

    for i, block in enumerate(all_blocks):
        bbox = block["bbox"]

        # ì´ë¯¸ ì¶”ê°€ëœ ë¸”ë¡ë“¤ê³¼ ë¹„êµ
        is_duplicate = False

        for existing in unique_blocks:
            iou = self._calculate_iou(bbox, existing["bbox"])

            # ì¤‘ë³µ íŒë‹¨ (IoU > 0.9)
            if iou > 0.9:
                is_duplicate = True
                break

        if not is_duplicate:
            unique_blocks.append(block)

    # 4. BoundingBoxë§Œ ì¶”ì¶œ
    result = [b["bbox"] for b in unique_blocks]

    return result
```

---

## ğŸ§ª Phase 3: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

### 3.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

**tests/test_multiscale.py**:

```python
import pytest
from pathlib import Path
import numpy as np
import cv2

from src.config import Config
from src.multiscale_analyzer import MultiscaleAnalyzer
from src.data_models import Column, BoundingBox

class TestMultiscaleAnalyzer:
    """ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ë¶„ì„ê¸° ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def config(self):
        return Config.load()

    @pytest.fixture
    def analyzer(self, config):
        return MultiscaleAnalyzer(config)

    def test_scale_detection(self, analyzer):
        """ìŠ¤ì¼€ì¼ë³„ ê²€ì¶œ í…ŒìŠ¤íŠ¸"""

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
        image = np.ones((500, 500), dtype=np.uint8) * 255

        # í° ë¸”ë¡ ê·¸ë¦¬ê¸°
        cv2.rectangle(image, (50, 50), (450, 150), 0, -1)

        # ì‘ì€ ë¸”ë¡ ê·¸ë¦¬ê¸°
        cv2.rectangle(image, (60, 60), (100, 90), 0, -1)

        columns = [Column(id="C", x_min=0, x_max=500)]

        # í° ìŠ¤ì¼€ì¼ ê²€ì¶œ
        large_blocks = analyzer._detect_at_scale(
            image, columns, h_kernel=15, v_kernel=2
        )
        assert len(large_blocks) >= 1  # í° ë¸”ë¡ ê²€ì¶œ

        # ì‘ì€ ìŠ¤ì¼€ì¼ ê²€ì¶œ
        small_blocks = analyzer._detect_at_scale(
            image, columns, h_kernel=5, v_kernel=1
        )
        assert len(small_blocks) >= 2  # í° ë¸”ë¡ + ì‘ì€ ë¸”ë¡

    def test_iou_calculation(self, analyzer):
        """IoU ê³„ì‚° í…ŒìŠ¤íŠ¸"""

        bbox1 = BoundingBox(0, 0, 100, 100)
        bbox2 = BoundingBox(50, 50, 150, 150)

        iou = analyzer._calculate_iou(bbox1, bbox2)

        # êµì§‘í•©: 50Ã—50 = 2,500
        # í•©ì§‘í•©: 10,000 + 10,000 - 2,500 = 17,500
        # IoU = 2,500 / 17,500 = 0.142...

        assert 0.14 < iou < 0.15

    def test_duplicate_detection(self, analyzer):
        """ì¤‘ë³µ íŒë‹¨ í…ŒìŠ¤íŠ¸"""

        bbox1 = BoundingBox(0, 0, 100, 100)
        bbox2 = BoundingBox(2, 2, 102, 102)  # ê±°ì˜ ê°™ìŒ
        bbox3 = BoundingBox(200, 200, 300, 300)  # ì™„ì „íˆ ë‹¤ë¦„

        assert analyzer._is_duplicate(bbox1, bbox2, iou_threshold=0.85)
        assert not analyzer._is_duplicate(bbox1, bbox3, iou_threshold=0.85)

    def test_merge_blocks(self, analyzer):
        """ë¸”ë¡ ë³‘í•© í…ŒìŠ¤íŠ¸"""

        blocks_by_scale = {
            "large": [
                BoundingBox(0, 0, 200, 100),
            ],
            "medium": [
                BoundingBox(0, 0, 100, 100),
                BoundingBox(100, 0, 200, 100),
            ],
            "small": [
                BoundingBox(0, 0, 50, 50),
                BoundingBox(50, 0, 100, 100),
                BoundingBox(100, 0, 150, 50),
            ],
        }

        merged = analyzer._merge_with_hierarchy(blocks_by_scale)

        # ì¤‘ë³µ ì œê±°ë˜ì–´ì•¼ í•¨
        # largeì˜ [0,0,200,100]ê³¼ mediumì˜ ë‘ ë¸”ë¡ì´ í•©ì³ì§„ ê²ƒê³¼ ì¤‘ë³µ
        # â†’ ì‹¤ì œë¡œëŠ” ì„¸ë°€í•œ ë¸”ë¡ë“¤ì´ ìš°ì„ 

        assert len(merged) > 0
        print(f"Merged blocks: {len(merged)}")
```

### 3.2 í†µí•© í…ŒìŠ¤íŠ¸

**tests/test_multiscale_pipeline.py**:

```python
def test_full_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

    config = Config.load()
    pdf_processor = PDFProcessor(config)
    multiscale_analyzer = MultiscaleAnalyzer(config)

    # 1. PDF â†’ ì´ë¯¸ì§€
    pdf_path = Path("test.pdf")
    image_paths = pdf_processor.convert_pdf_to_images(
        pdf_path, "test_multiscale"
    )

    # 2. ì²« í˜ì´ì§€ ë¡œë“œ
    image = cv2.imread(str(image_paths[0]), cv2.IMREAD_GRAYSCALE)

    # 3. ì»¬ëŸ¼ ê²€ì¶œ
    columns = [
        Column(id="L", x_min=0, x_max=image.shape[1]//2),
        Column(id="R", x_min=image.shape[1]//2, x_max=image.shape[1])
    ]

    # 4. ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ê²€ì¶œ
    blocks = multiscale_analyzer.detect_all_blocks(
        image, columns, use_tiny=True
    )

    print(f"Detected blocks: {len(blocks)}")

    # 5. ê²€ì¦
    assert len(blocks) > 89  # í˜„ì¬(89ê°œ)ë³´ë‹¤ ë§ì•„ì•¼ í•¨
    assert len(blocks) < 200  # ê³¼ë„í•œ íŒŒí¸í™”ëŠ” ì•„ë‹ˆì–´ì•¼ í•¨

    # 6. ìŠ¤ì¼€ì¼ë³„ ë¶„í¬ í™•ì¸
    scales = {}
    for block in blocks:
        scale = block.get("scale", "unknown")
        scales[scale] = scales.get(scale, 0) + 1

    print(f"Blocks by scale: {scales}")
```

### 3.3 ì‹œê°í™” í…ŒìŠ¤íŠ¸

**tests/visualize_multiscale.py**:

```python
def visualize_multiscale_results():
    """
    ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ê²°ê³¼ë¥¼ ì‹œê°í™”

    ê° ìŠ¤ì¼€ì¼ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ í‘œì‹œ
    """

    config = Config.load()
    multiscale_analyzer = MultiscaleAnalyzer(config)

    # ì´ë¯¸ì§€ ë¡œë“œ
    image_path = Path("dataset_root/documents/test_doc/pages/page_0000.png")
    image = cv2.imread(str(image_path))

    # ì»¬ëŸ¼ ì •ì˜
    columns = [
        Column(id="L", x_min=0, x_max=image.shape[1]//2),
        Column(id="R", x_min=image.shape[1]//2, x_max=image.shape[1])
    ]

    # ìŠ¤ì¼€ì¼ë³„ ê²€ì¶œ
    blocks_by_scale = {}

    for scale in multiscale_analyzer.scales:
        blocks = multiscale_analyzer._detect_at_scale(
            cv2.cvtColor(image, cv2.COLOR_BGR2GRAY),
            columns,
            scale["h_kernel"],
            scale["v_kernel"]
        )
        blocks_by_scale[scale["name"]] = blocks
        print(f"{scale['name']}: {len(blocks)} blocks")

    # ì‹œê°í™”
    colors = {
        "large": (255, 0, 0),      # íŒŒë€ìƒ‰
        "medium": (0, 255, 0),     # ì´ˆë¡ìƒ‰
        "small": (0, 0, 255),      # ë¹¨ê°„ìƒ‰
        "tiny": (255, 255, 0),     # ì²­ë¡ìƒ‰
    }

    vis_image = image.copy()

    for scale_name, blocks in blocks_by_scale.items():
        color = colors.get(scale_name, (128, 128, 128))

        for bbox in blocks:
            cv2.rectangle(
                vis_image,
                (bbox.x_min, bbox.y_min),
                (bbox.x_max, bbox.y_max),
                color,
                2
            )

    # ì €ì¥
    output_path = Path("dataset_root/multiscale_visualization.png")
    cv2.imwrite(str(output_path), vis_image)
    print(f"Saved visualization: {output_path}")
```

---

## ğŸ“Š Phase 4: ì„±ëŠ¥ ìµœì í™”

### 4.1 ë³‘ë ¬ ì²˜ë¦¬

**ìŠ¤ì¼€ì¼ë³„ ê²€ì¶œì„ ë³‘ë ¬ë¡œ**:

```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def detect_all_blocks_parallel(
    self,
    image: np.ndarray,
    columns: List[Column],
    use_tiny: bool = False
) -> List[Block]:
    """
    ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ í–¥ìƒ
    """

    scales_to_use = self.scales[:-1] if not use_tiny else self.scales

    # ë³‘ë ¬ ì‹¤í–‰
    blocks_by_scale = {}

    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = {}

        for scale in scales_to_use:
            future = executor.submit(
                self._detect_at_scale,
                image,
                columns,
                scale["h_kernel"],
                scale["v_kernel"]
            )
            futures[future] = scale["name"]

        for future in as_completed(futures):
            scale_name = futures[future]
            blocks = future.result()
            blocks_by_scale[scale_name] = blocks

    # ë³‘í•©
    merged_blocks = self._merge_with_hierarchy(blocks_by_scale)

    return merged_blocks
```

### 4.2 ìºì‹±

**ì¤‘ê°„ ê²°ê³¼ ìºì‹±**:

```python
from functools import lru_cache
import hashlib

def _get_image_hash(self, image: np.ndarray) -> str:
    """ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚° (ìºì‹±ìš©)"""
    return hashlib.md5(image.tobytes()).hexdigest()

def detect_all_blocks_cached(
    self,
    image: np.ndarray,
    columns: List[Column],
    use_tiny: bool = False
) -> List[Block]:
    """
    ìºì‹±ì„ ì‚¬ìš©í•œ ê²€ì¶œ

    ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•´ ì¬ê²€ì¶œí•˜ì§€ ì•ŠìŒ
    """

    image_hash = self._get_image_hash(image)
    cache_key = f"{image_hash}_{use_tiny}"

    if cache_key in self._cache:
        return self._cache[cache_key]

    blocks = self.detect_all_blocks_parallel(image, columns, use_tiny)

    self._cache[cache_key] = blocks

    return blocks
```

---

## ğŸ›ï¸ Phase 5: íŒŒë¼ë¯¸í„° íŠœë‹

### 5.1 ìŠ¤ì¼€ì¼ ì„¤ì • ìµœì í™”

**ì‹¤í—˜í•  ì¡°í•©**:

```python
# ì¡°í•© 1: 3ë‹¨ê³„ (ë¹ ë¦„, ê· í˜•)
scales_3 = [
    {"name": "large", "h_kernel": 15, "v_kernel": 2},
    {"name": "medium", "h_kernel": 10, "v_kernel": 2},
    {"name": "small", "h_kernel": 6, "v_kernel": 1},
]

# ì¡°í•© 2: 4ë‹¨ê³„ (ê¶Œì¥, ì •ë°€)
scales_4 = [
    {"name": "large", "h_kernel": 15, "v_kernel": 2},
    {"name": "medium", "h_kernel": 10, "v_kernel": 2},
    {"name": "small", "h_kernel": 7, "v_kernel": 2},
    {"name": "tiny", "h_kernel": 5, "v_kernel": 1},
]

# ì¡°í•© 3: 5ë‹¨ê³„ (ë§¤ìš° ì •ë°€, ëŠë¦¼)
scales_5 = [
    {"name": "xlarge", "h_kernel": 20, "v_kernel": 3},
    {"name": "large", "h_kernel": 15, "v_kernel": 2},
    {"name": "medium", "h_kernel": 10, "v_kernel": 2},
    {"name": "small", "h_kernel": 7, "v_kernel": 2},
    {"name": "tiny", "h_kernel": 5, "v_kernel": 1},
]
```

### 5.2 IoU ì„ê³„ê°’ ì¡°ì •

**ì‹¤í—˜**:

```python
# ì¤‘ë³µ íŒë‹¨ ì„ê³„ê°’
iou_thresholds = [0.75, 0.80, 0.85, 0.90, 0.95]

for threshold in iou_thresholds:
    blocks = multiscale_analyzer.detect_all_blocks(
        image, columns, iou_threshold=threshold
    )
    print(f"IoU={threshold}: {len(blocks)} blocks")

# ì˜ˆìƒ ê²°ê³¼:
# IoU=0.75: 120ê°œ (ì¤‘ë³µ ë§ì´ ì œê±°)
# IoU=0.85: 135ê°œ (ê· í˜•) â† ê¶Œì¥
# IoU=0.95: 150ê°œ (ê±°ì˜ ì œê±° ì•ˆ í•¨)
```

### 5.3 ìµœì†Œ ë¸”ë¡ í¬ê¸° ì¡°ì •

**ìŠ¤ì¼€ì¼ë³„ ìµœì ê°’ ì°¾ê¸°**:

```python
min_sizes = {
    "large": [300, 400, 500],
    "medium": [200, 300, 400],
    "small": [150, 200, 250],
    "tiny": [50, 100, 150],
}

# ê° ì¡°í•© í…ŒìŠ¤íŠ¸
for large_min in min_sizes["large"]:
    for medium_min in min_sizes["medium"]:
        for small_min in min_sizes["small"]:
            for tiny_min in min_sizes["tiny"]:
                # í…ŒìŠ¤íŠ¸...
                pass
```

---

## ğŸ“ˆ Phase 6: í‰ê°€ ë° ë¹„êµ

### 6.1 ì •ëŸ‰ì  í‰ê°€

**ì§€í‘œ**:

```python
def evaluate_detection(blocks: List[Block], ground_truth: List[Block]):
    """
    ê²€ì¶œ ê²°ê³¼ í‰ê°€

    Metrics:
    - Precision: ì •í™•ë„
    - Recall: ì¬í˜„ìœ¨
    - F1-Score: ì¡°í™”í‰ê· 
    - Block count: ë¸”ë¡ ìˆ˜
    """

    TP = 0  # True Positive
    FP = 0  # False Positive
    FN = 0  # False Negative

    for gt_block in ground_truth:
        matched = False
        for detected_block in blocks:
            iou = calculate_iou(gt_block.bbox, detected_block.bbox)
            if iou > 0.5:
                TP += 1
                matched = True
                break

        if not matched:
            FN += 1

    FP = len(blocks) - TP

    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return {
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "block_count": len(blocks),
        "TP": TP,
        "FP": FP,
        "FN": FN
    }
```

### 6.2 ë²„ì „ ë¹„êµ

**í˜„ì¬ ë°©ì‹ vs ë‹¤ì¸µ ìŠ¤ì¼€ì¼**:

```python
def compare_methods():
    """
    í˜„ì¬ ë°©ì‹ê³¼ ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ë¹„êµ
    """

    config = Config.load()

    # í˜„ì¬ ë°©ì‹ (h_kernel=10)
    current_analyzer = DensityAnalyzer(config, use_projection=False)
    current_blocks = current_analyzer.analyze_page(image, 0)

    # ë‹¤ì¸µ ìŠ¤ì¼€ì¼
    multiscale_analyzer = MultiscaleAnalyzer(config)
    multiscale_blocks = multiscale_analyzer.detect_all_blocks(
        image, current_blocks.columns
    )

    print("=== ë¹„êµ ===")
    print(f"í˜„ì¬ ë°©ì‹: {len(current_blocks.blocks)}ê°œ")
    print(f"ë‹¤ì¸µ ìŠ¤ì¼€ì¼: {len(multiscale_blocks)}ê°œ")
    print(f"ì¦ê°€: +{len(multiscale_blocks) - len(current_blocks.blocks)}ê°œ")

    # ìŠ¤ì¼€ì¼ë³„ ë¶„í¬
    scales = {}
    for block in multiscale_blocks:
        scale = block.scale
        scales[scale] = scales.get(scale, 0) + 1

    print(f"\nìŠ¤ì¼€ì¼ë³„ ë¶„í¬:")
    for scale, count in scales.items():
        print(f"  {scale}: {count}ê°œ")
```

---

## ğŸš€ Phase 7: ë°°í¬ ë° í†µí•©

### 7.1 ê¸°ì¡´ ì½”ë“œ í†µí•©

**density_analyzer.py ìˆ˜ì •**:

```python
class DensityAnalyzer:
    """ë°€ì§‘ë„ ê¸°ë°˜ ë¸”ë¡ ê²€ì¶œ"""

    def __init__(
        self,
        config: Config,
        use_projection: bool = False,
        use_multiscale: bool = False  # ìƒˆë¡œìš´ ì˜µì…˜
    ):
        self.config = config
        self.use_projection = use_projection
        self.use_multiscale = use_multiscale

        if use_multiscale:
            from multiscale_analyzer import MultiscaleAnalyzer
            self.multiscale_analyzer = MultiscaleAnalyzer(config)

    def analyze_page(
        self,
        image: np.ndarray,
        page_index: int
    ) -> PageData:
        """í˜ì´ì§€ ë¶„ì„"""

        # ... ê¸°ì¡´ ì½”ë“œ ...

        if self.use_multiscale:
            # ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ì‚¬ìš©
            bboxes = self.multiscale_analyzer.detect_all_blocks(
                mask, columns
            )
        elif self.use_projection:
            # íˆ¬ì˜ ë¶„ì„ ì‚¬ìš©
            bboxes = self._find_blocks_with_projection(mask, columns)
        else:
            # ê¸°ë³¸ ëª¨í´ë¡œì§€ ì‚¬ìš©
            bboxes = self._find_blocks(mask)

        # ... ë‚˜ë¨¸ì§€ ì½”ë“œ ...
```

### 7.2 ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸

**.env íŒŒì¼**:

```bash
# ë¸”ë¡ ê²€ì¶œ ë°©ì‹
USE_MULTISCALE=true
MULTISCALE_USE_TINY=false  # ì´ˆì†Œí˜• ìŠ¤ì¼€ì¼ ì‚¬ìš© ì—¬ë¶€

# ë‹¤ì¸µ ìŠ¤ì¼€ì¼ íŒŒë¼ë¯¸í„°
MULTISCALE_LARGE_H=15
MULTISCALE_MEDIUM_H=10
MULTISCALE_SMALL_H=7
MULTISCALE_TINY_H=5

# ë³‘í•© íŒŒë¼ë¯¸í„°
MULTISCALE_IOU_THRESHOLD=0.85
```

### 7.3 í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ì—…ë°ì´íŠ¸

**tests/test_pipeline.py ìˆ˜ì •**:

```python
def main():
    """Phase 1 í†µí•© í…ŒìŠ¤íŠ¸"""

    # ... ê¸°ì¡´ ì½”ë“œ ...

    # ë¸”ë¡ ê²€ì¶œ (ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ì‚¬ìš©)
    analyzer = DensityAnalyzer(
        config,
        use_projection=False,
        use_multiscale=True  # ë‹¤ì¸µ ìŠ¤ì¼€ì¼ í™œì„±í™”
    )

    page_data = analyzer.analyze_page(image, 0)

    print(f"  [OK] {len(page_data.blocks)}ê°œ ë¸”ë¡ ê²€ì¶œ")

    # ìŠ¤ì¼€ì¼ë³„ í†µê³„
    scales = {}
    for block in page_data.blocks:
        scale = block.scale
        scales[scale] = scales.get(scale, 0) + 1

    print(f"\n  ìŠ¤ì¼€ì¼ë³„ ë¶„í¬:")
    for scale, count in sorted(scales.items()):
        print(f"    {scale}: {count}ê°œ")
```

---

## ğŸ“ Phase 8: ë¬¸ì„œí™”

### 8.1 ì‚¬ìš©ì ê°€ì´ë“œ

**docs/multiscale_guide.md**:

```markdown
# ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ë¸”ë¡ ê²€ì¶œ ê°€ì´ë“œ

## ê°œìš”

ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ê²€ì¶œì€ ì—¬ëŸ¬ ì»¤ë„ í¬ê¸°ë¡œ ë¸”ë¡ì„ ê²€ì¶œí•œ í›„ ë³‘í•©í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
ì´ë¥¼ í†µí•´ **ëª¨ë“  í¬ê¸°ì˜ ë¸”ë¡ì„ ë¹ ì§ì—†ì´ ê²€ì¶œ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì‚¬ìš© ë°©ë²•

### 1. í™œì„±í™”

`.env` íŒŒì¼:
```bash
USE_MULTISCALE=true
```

### 2. íŒŒë¼ë¯¸í„° ì¡°ì •

```bash
# ìŠ¤ì¼€ì¼ ì •ì˜
MULTISCALE_LARGE_H=15   # í° êµ¬ì¡°
MULTISCALE_MEDIUM_H=10  # ì¤‘ê°„ êµ¬ì¡°
MULTISCALE_SMALL_H=7    # ì‘ì€ êµ¬ì¡°
MULTISCALE_TINY_H=5     # ì´ˆì†Œí˜• êµ¬ì¡° (ì„ íƒì )

# ì´ˆì†Œí˜• ìŠ¤ì¼€ì¼ ì‚¬ìš© ì—¬ë¶€
MULTISCALE_USE_TINY=false  # trueë©´ ë” ì„¸ë°€

# ì¤‘ë³µ ì œê±° ì„ê³„ê°’
MULTISCALE_IOU_THRESHOLD=0.85  # ë‚®ì„ìˆ˜ë¡ ì—„ê²©
```

### 3. ì‹¤í–‰

```bash
python tests/test_pipeline.py
```

## ê²°ê³¼ í•´ì„

- **large**: í° êµ¬ì¡° (ì œëª©, ë¬¸ë‹¨ ì „ì²´ ë“±)
- **medium**: ì¤‘ê°„ êµ¬ì¡° (ë¬¸ì¥, ë¼ì¸ ë“±)
- **small**: ì‘ì€ êµ¬ì¡° (ë‹¨ì–´, ë³´ê¸° ë“±)
- **tiny**: ì´ˆì†Œí˜• êµ¬ì¡° (ê¸°í˜¸, ë‹¨ìœ„ ë“±)

## íŠœë‹ ê°€ì´ë“œ

### ë¸”ë¡ ìˆ˜ê°€ ë„ˆë¬´ ë§ì„ ë•Œ
â†’ `MULTISCALE_IOU_THRESHOLD`ë¥¼ ë‚®ì¶”ê¸° (0.85 â†’ 0.80)
â†’ `MULTISCALE_USE_TINY`ë¥¼ falseë¡œ

### ë¸”ë¡ ìˆ˜ê°€ ë„ˆë¬´ ì ì„ ë•Œ
â†’ `MULTISCALE_USE_TINY`ë¥¼ trueë¡œ
â†’ ìŠ¤ì¼€ì¼ ì¶”ê°€ (xlarge, xsmall ë“±)

### ì„±ëŠ¥ ë¬¸ì œ
â†’ ìŠ¤ì¼€ì¼ ê°œìˆ˜ ì¤„ì´ê¸° (4ê°œ â†’ 3ê°œ)
â†’ ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
```

### 8.2 API ë¬¸ì„œ

**docs/api_multiscale.md**:

```markdown
# MultiscaleAnalyzer API

## í´ë˜ìŠ¤

### `MultiscaleAnalyzer`

ë‹¤ì¸µ ìŠ¤ì¼€ì¼ ë¸”ë¡ ê²€ì¶œê¸°.

#### ìƒì„±ì

```python
MultiscaleAnalyzer(config: Config)
```

#### ë©”ì„œë“œ

##### `detect_all_blocks()`

```python
def detect_all_blocks(
    self,
    image: np.ndarray,
    columns: List[Column],
    use_tiny: bool = False
) -> List[Block]
```

**Parameters:**
- `image`: í˜ì´ì§€ ì´ë¯¸ì§€ (grayscale)
- `columns`: ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
- `use_tiny`: ì´ˆì†Œí˜• ìŠ¤ì¼€ì¼ ì‚¬ìš© ì—¬ë¶€

**Returns:**
- ê²€ì¶œëœ ë¸”ë¡ ë¦¬ìŠ¤íŠ¸

**Example:**
```python
analyzer = MultiscaleAnalyzer(config)
blocks = analyzer.detect_all_blocks(image, columns, use_tiny=True)
```
```

---

## â±ï¸ ì¼ì • ë° ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì „ì²´ ì¼ì • (4-5ì‹œê°„)

```
Phase 1: ì•„í‚¤í…ì²˜ ì„¤ê³„ (30ë¶„)
  âœ“ MultiscaleAnalyzer í´ë˜ìŠ¤ ì„¤ê³„
  âœ“ ë°ì´í„° ëª¨ë¸ í™•ì¥

Phase 2: í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ (2ì‹œê°„)
  âœ“ _detect_at_scale() êµ¬í˜„
  âœ“ _calculate_iou() êµ¬í˜„
  âœ“ _is_duplicate() êµ¬í˜„
  âœ“ _merge_with_hierarchy() êµ¬í˜„

Phase 3: í…ŒìŠ¤íŠ¸ (1ì‹œê°„)
  âœ“ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
  âœ“ í†µí•© í…ŒìŠ¤íŠ¸
  âœ“ ì‹œê°í™” í…ŒìŠ¤íŠ¸

Phase 4: ìµœì í™” (30ë¶„)
  âœ“ ë³‘ë ¬ ì²˜ë¦¬
  âœ“ ìºì‹± (ì„ íƒì )

Phase 5: íŒŒë¼ë¯¸í„° íŠœë‹ (30ë¶„)
  âœ“ ìŠ¤ì¼€ì¼ ì¡°í•© ì‹¤í—˜
  âœ“ IoU ì„ê³„ê°’ ì‹¤í—˜

Phase 6: í‰ê°€ (30ë¶„)
  âœ“ ì •ëŸ‰ì  í‰ê°€
  âœ“ ë²„ì „ ë¹„êµ

Phase 7: ë°°í¬ (30ë¶„)
  âœ“ ê¸°ì¡´ ì½”ë“œ í†µí•©
  âœ“ ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸
  âœ“ í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ ìˆ˜ì •

Phase 8: ë¬¸ì„œí™” (30ë¶„)
  âœ“ ì‚¬ìš©ì ê°€ì´ë“œ
  âœ“ API ë¬¸ì„œ
```

### ì²´í¬ë¦¬ìŠ¤íŠ¸

**Phase 1**:
- [ ] `src/multiscale_analyzer.py` ìƒì„±
- [ ] `MultiscaleAnalyzer` í´ë˜ìŠ¤ êµ¬ì¡° ì‘ì„±
- [ ] `data_models.py`ì— `scale`, `parent_id`, `children_ids` ì¶”ê°€

**Phase 2**:
- [ ] `_detect_at_scale()` êµ¬í˜„
- [ ] `_calculate_iou()` êµ¬í˜„
- [ ] `_is_duplicate()` êµ¬í˜„
- [ ] `_merge_with_hierarchy()` êµ¬í˜„
- [ ] `_get_min_size_for_scale()` êµ¬í˜„

**Phase 3**:
- [ ] `tests/test_multiscale.py` ì‘ì„±
- [ ] `tests/test_multiscale_pipeline.py` ì‘ì„±
- [ ] `tests/visualize_multiscale.py` ì‘ì„±
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸

**Phase 4**:
- [ ] `detect_all_blocks_parallel()` êµ¬í˜„ (ì„ íƒì )
- [ ] ìºì‹± ì¶”ê°€ (ì„ íƒì )

**Phase 5**:
- [ ] ìŠ¤ì¼€ì¼ ì¡°í•© 3-4ê°€ì§€ ì‹¤í—˜
- [ ] IoU ì„ê³„ê°’ 0.75-0.95 ì‹¤í—˜
- [ ] ìµœì  íŒŒë¼ë¯¸í„° í™•ì •

**Phase 6**:
- [ ] í‰ê°€ í•¨ìˆ˜ êµ¬í˜„
- [ ] í˜„ì¬ ë°©ì‹ê³¼ ë¹„êµ
- [ ] ê²°ê³¼ ë¦¬í¬íŠ¸ ì‘ì„±

**Phase 7**:
- [ ] `density_analyzer.py`ì— `use_multiscale` ì˜µì…˜ ì¶”ê°€
- [ ] `.env` íŒŒì¼ì— ì„¤ì • ì¶”ê°€
- [ ] `test_pipeline.py` ìˆ˜ì •

**Phase 8**:
- [ ] ì‚¬ìš©ì ê°€ì´ë“œ ì‘ì„±
- [ ] API ë¬¸ì„œ ì‘ì„±
- [ ] README ì—…ë°ì´íŠ¸

---

## ğŸ¯ ì˜ˆìƒ ê²°ê³¼

### ì •ëŸ‰ì  ëª©í‘œ

**í˜„ì¬ (h_kernel=10)**:
- ë¸”ë¡ ìˆ˜: 89ê°œ
- í’ˆì§ˆ: 92%

**ë‹¤ì¸µ ìŠ¤ì¼€ì¼ (3ë‹¨ê³„)**:
- ë¸”ë¡ ìˆ˜: 110-130ê°œ
- í’ˆì§ˆ: 95%+
- ì¶”ê°€ ê²€ì¶œ: +21-41ê°œ (24-46% ì¦ê°€)

**ë‹¤ì¸µ ìŠ¤ì¼€ì¼ (4ë‹¨ê³„ + tiny)**:
- ë¸”ë¡ ìˆ˜: 130-150ê°œ
- í’ˆì§ˆ: 97%+
- ì¶”ê°€ ê²€ì¶œ: +41-61ê°œ (46-68% ì¦ê°€)

### ì •ì„±ì  ëª©í‘œ

**ê²€ì¶œ ê°€ëŠ¥í•œ ìš”ì†Œ**:
- âœ… í° êµ¬ì¡°: ë¬¸ì œ ì „ì²´, í‘œ ì „ì²´
- âœ… ì¤‘ê°„ êµ¬ì¡°: ë¬¸ì¥, ë¼ì¸, ë¬¸ë‹¨
- âœ… ì‘ì€ êµ¬ì¡°: ë‹¨ì–´, ë³´ê¸°, ë¬¸ì œ ë²ˆí˜¸
- âœ… ì´ˆì†Œí˜• êµ¬ì¡°: ê¸°í˜¸, ë‹¨ìœ„, ê´„í˜¸

**ë†“ì¹˜ì§€ ì•ŠëŠ” ê²ƒ**:
- âœ… í‘œ ë‚´ë¶€ ì…€
- âœ… ë³µí•© ë³´ê¸°ì˜ ì„¸ë¶€ í•­ëª©
- âœ… ìˆ˜ì‹ì˜ êµ¬ì„± ìš”ì†Œ (ì„ íƒì )
- âœ… ì‘ì€ ë‹¨ìœ„, ê¸°í˜¸

---

## ğŸ›¡ï¸ ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘

### ìœ„í—˜ 1: ê³¼ë„í•œ ë¸”ë¡ ìˆ˜

**ì¦ìƒ**: 150ê°œ ì´ìƒ

**ì›ì¸**: IoU ì„ê³„ê°’ì´ ë„ˆë¬´ ë†’ìŒ, tiny ìŠ¤ì¼€ì¼ ì‚¬ìš©

**ëŒ€ì‘**:
- IoU ì„ê³„ê°’ ë‚®ì¶”ê¸° (0.85 â†’ 0.80)
- tiny ìŠ¤ì¼€ì¼ ë¹„í™œì„±í™”
- ìŠ¤ì¼€ì¼ ê°œìˆ˜ ì¤„ì´ê¸° (4ê°œ â†’ 3ê°œ)

### ìœ„í—˜ 2: ì„±ëŠ¥ ì €í•˜

**ì¦ìƒ**: ì²˜ë¦¬ ì‹œê°„ > 5ì´ˆ/í˜ì´ì§€

**ì›ì¸**: ìŠ¤ì¼€ì¼ì´ ë„ˆë¬´ ë§ìŒ, ë³‘ë ¬ ì²˜ë¦¬ ë¯¸ì‚¬ìš©

**ëŒ€ì‘**:
- ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”
- ìŠ¤ì¼€ì¼ ê°œìˆ˜ ì¤„ì´ê¸°
- ìºì‹± í™œìš©

### ìœ„í—˜ 3: ì—¬ì „íˆ ëˆ„ë½ ì¡´ì¬

**ì¦ìƒ**: ì‚¬ìš©ìê°€ "ì•„ì§ë„ ë¶€ì¡±"

**ì›ì¸**: íŠ¹ìˆ˜í•œ êµ¬ì¡°, ë§¤ìš° ì‘ì€ ìš”ì†Œ

**ëŒ€ì‘**:
- tiny ìŠ¤ì¼€ì¼ í™œì„±í™”
- ìµœì†Œ ë¸”ë¡ í¬ê¸° ë‚®ì¶”ê¸°
- ìŠ¤ì¼€ì¼ ì¶”ê°€ (h_kernel=3 ë“±)

---

## ğŸ“Š ì„±ê³µ ê¸°ì¤€

**ìµœì†Œ ì„±ê³µ ê¸°ì¤€**:
- [ ] ë¸”ë¡ ìˆ˜ > 110ê°œ (í˜„ì¬ ëŒ€ë¹„ +20% ì´ìƒ)
- [ ] ì‚¬ìš©ì ë§Œì¡± ("ëˆ„ë½ ì—†ìŒ" í™•ì¸)
- [ ] ì²˜ë¦¬ ì‹œê°„ < 3ì´ˆ/í˜ì´ì§€

**ì´ìƒì  ì„±ê³µ ê¸°ì¤€**:
- [ ] ë¸”ë¡ ìˆ˜ 120-140ê°œ
- [ ] ëª¨ë“  ìŠ¤ì¼€ì¼ì˜ ìš”ì†Œ ê²€ì¶œ
- [ ] Recall > 95%
- [ ] ì²˜ë¦¬ ì‹œê°„ < 2ì´ˆ/í˜ì´ì§€

---

**ì‘ì„±ì**: Claude Code (Opus)
**ê³„íš ìƒì„¸ë„**: â­â­â­â­â­ (5/5)
**ì‹¤í–‰ ê°€ëŠ¥ì„±**: â­â­â­â­â­ (5/5)
**ì˜ˆìƒ ì„±ê³µë¥ **: 95%+
**ë‹¤ìŒ ë‹¨ê³„**: ì‚¬ìš©ì ìŠ¹ì¸ í›„ Phase 1 ì‹œì‘
