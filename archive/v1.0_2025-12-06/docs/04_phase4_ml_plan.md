# Phase 4: ML ê¸°ë°˜ ìë™ ê·¸ë£¹í•‘ ê³„íš

**ëª©í‘œ:** ì‚¬ìš©ì ë¼ë²¨ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ìë™ ë¬¸ì œ ë¶„í• 

**ìƒíƒœ:** ğŸ’¡ **ì¥ê¸° ê³„íš**

**ì˜ˆìƒ ê¸°ê°„:** ìˆ˜ê°œì›”

**ì„ í–‰ ì¡°ê±´:** Phase 3 ì™„ë£Œ + ì¶©ë¶„í•œ ë¼ë²¨ ë°ì´í„° ìˆ˜ì§‘

---

## ğŸ¯ ëª©í‘œ

### ìµœì¢… ë¹„ì „
ì‚¬ìš©ìê°€ PDFë¥¼ ë„£ìœ¼ë©´:
1. ìë™ìœ¼ë¡œ ë¸”ë¡ ê²€ì¶œ (Phase 1 ì™„ë£Œ âœ…)
2. **ìë™ìœ¼ë¡œ ë¬¸ì œ ë‹¨ìœ„ ê·¸ë£¹í•‘** (Phase 4 ëª©í‘œ)
3. ê·¸ë£¹ë³„ ì´ë¯¸ì§€ í¬ë¡­ ë° ì €ì¥
4. (ì„ íƒ) ì‚¬ìš©ìê°€ ìˆ˜ì • â†’ ì¬í•™ìŠµ â†’ ì„±ëŠ¥ ê°œì„ 

### ë‹¨ê³„ì  ë°œì „
```
ê·œì¹™ ê¸°ë°˜ (Baseline)
    â†“
ê¸°ê³„ í•™ìŠµ (ML)
    â†“
ë”¥ëŸ¬ë‹ (DL)
```

---

## ğŸ“Š í•™ìŠµ ë°ì´í„°

### ì…ë ¥ (Features)
**ë¸”ë¡ ì •ë³´ (Phase 1ì—ì„œ ì¶”ì¶œ):**
- ìœ„ì¹˜: `x_min, y_min, x_max, y_max`
- í¬ê¸°: `width, height, area`
- ë°€ì§‘ë„: `pixel_density`
- ìŠ¤ì¼€ì¼: `scale` ("large", "medium", "small", "ultra_small")
- ì»¬ëŸ¼: `column` ("L" or "R")

**ë¸”ë¡ ê°„ ê´€ê³„:**
- Y ë°©í–¥ ê°„ê²©: `gap_y = next_block.y_min - current_block.y_max`
- X ë°©í–¥ ê°„ê²©: `gap_x = ...`
- ì¤‘ì‹¬ì  ì •ë ¬ë„: `abs(center_x1 - center_x2)`

**ê³„ì¸µ êµ¬ì¡° (Phase 1ì—ì„œ ì¶”ì¶œ):**
- `parent_id`: ë¶€ëª¨ ë¸”ë¡ ID
- `children_ids`: ìì‹ ë¸”ë¡ ID ëª©ë¡

**ë¬¸ë§¥ ì •ë³´:**
- ì´ì „ ë¸”ë¡ê¹Œì§€ì˜ ëˆ„ì  ì •ë³´
- í˜ì´ì§€ ë‚´ ìœ„ì¹˜ ë¹„ìœ¨ (ìƒ/ì¤‘/í•˜)
- ì»¬ëŸ¼ ë‚´ ìˆœì„œ

### ì¶œë ¥ (Labels)
**ê·¸ë£¹ ê²½ê³„ (Phase 3ì—ì„œ ìˆ˜ì§‘):**
- `is_group_start`: ì´ ë¸”ë¡ì´ ìƒˆ ë¬¸ì œì˜ ì‹œì‘ì¸ê°€? (True/False)
- `group_id`: ì–´ëŠ ê·¸ë£¹ì— ì†í•˜ëŠ”ê°€? ("L1", "L2", ...)

**ì˜ˆì‹œ ë°ì´í„°:**
```json
{
  "block_id": 5,
  "features": {
    "y_min": 450,
    "height": 30,
    "density": 0.65,
    "scale": "small",
    "gap_from_prev": 15  // ì´ì „ ë¸”ë¡ê³¼ì˜ ê°„ê²©
  },
  "label": {
    "is_group_start": false,  // ì´ì „ ë¸”ë¡ê³¼ ê°™ì€ ë¬¸ì œ
    "group_id": "L1"
  }
}
```

---

## ğŸ§  ì ‘ê·¼ë²•

### Approach 1: ê·œì¹™ ê¸°ë°˜ (Baseline)

**ì „ëµ:** Y ì¢Œí‘œ ê°„ê²© ê¸°ë°˜ ë¶„í• 

**ì•Œê³ ë¦¬ì¦˜:**
```python
def rule_based_grouping(blocks: List[Block], threshold: int = 50) -> List[ProblemGroup]:
    """
    ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ê·¸ë£¹í•‘

    ê·œì¹™:
      - Y ë°©í–¥ ê°„ê²©ì´ thresholdë³´ë‹¤ í¬ë©´ ìƒˆ ë¬¸ì œ ì‹œì‘
      - ê°™ì€ ì»¬ëŸ¼ ë‚´ì—ì„œë§Œ ë¬¶ìŒ
    """
    groups = []
    current_group_blocks = []

    blocks_sorted = sorted(blocks, key=lambda b: b.bbox.y_min)

    for i, block in enumerate(blocks_sorted):
        if i == 0:
            current_group_blocks.append(block)
            continue

        prev_block = blocks_sorted[i - 1]

        # ê°„ê²© ê³„ì‚°
        gap = block.bbox.y_min - prev_block.bbox.y_max

        # ì»¬ëŸ¼ì´ ë‹¤ë¥´ê±°ë‚˜ ê°„ê²©ì´ í¬ë©´ ìƒˆ ê·¸ë£¹
        if block.column != prev_block.column or gap > threshold:
            # í˜„ì¬ ê·¸ë£¹ ì €ì¥
            if current_group_blocks:
                groups.append(create_group(current_group_blocks))
                current_group_blocks = []

        current_group_blocks.append(block)

    # ë§ˆì§€ë§‰ ê·¸ë£¹
    if current_group_blocks:
        groups.append(create_group(current_group_blocks))

    return groups
```

**ì¥ì :**
- êµ¬í˜„ ê°„ë‹¨
- ì„¤ëª… ê°€ëŠ¥
- ë¹ ë¥¸ ì‹¤í–‰

**ë‹¨ì :**
- ë³µì¡í•œ ë ˆì´ì•„ì›ƒ ëŒ€ì‘ ì–´ë ¤ì›€
- í•˜ë‚˜ì˜ thresholdë¡œ ëª¨ë“  ê²½ìš° ì»¤ë²„ ë¶ˆê°€

**ì˜ˆìƒ ì„±ëŠ¥:**
- Precision: ~70%
- Recall: ~60%
- F1-Score: ~65%

---

### Approach 2: ê¸°ê³„ í•™ìŠµ (ML)

**ëª¨ë¸ í›„ë³´:**
1. **Random Forest**
   - ì¥ì : í•´ì„ ê°€ëŠ¥, ë¹ ë¦„, ê³¼ì í•© ì ìŒ
   - ë‹¨ì : ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ì–´ë ¤ì›€

2. **XGBoost / LightGBM**
   - ì¥ì : ë†’ì€ ì„±ëŠ¥, ë¹ ë¥¸ í•™ìŠµ
   - ë‹¨ì : í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”

3. **CRF (Conditional Random Fields)**
   - ì¥ì : ìˆœì°¨ ë°ì´í„°ì— ê°•í•¨
   - ë‹¨ì : íŠ¹ì§• ê³µí•™ í•„ìš”

**íŠ¹ì§• (Features):**
```python
def extract_features(block, prev_block, page_data):
    return {
        # ë¸”ë¡ ìì²´ íŠ¹ì§•
        "height": block.bbox.height,
        "width": block.bbox.width,
        "area": block.bbox.area,
        "density": block.pixel_density,
        "scale": encode_scale(block.scale),
        "column": encode_column(block.column),

        # ìœ„ì¹˜ íŠ¹ì§•
        "y_position_ratio": block.bbox.y_min / page_data.height,
        "x_center": (block.bbox.x_min + block.bbox.x_max) / 2,

        # ì´ì „ ë¸”ë¡ê³¼ì˜ ê´€ê³„
        "gap_y": block.bbox.y_min - prev_block.bbox.y_max if prev_block else 0,
        "gap_x_center": abs(x_center_current - x_center_prev),
        "density_diff": abs(block.pixel_density - prev_block.pixel_density),
        "height_ratio": block.bbox.height / prev_block.bbox.height,

        # ë¬¸ë§¥ íŠ¹ì§•
        "blocks_before": count_blocks_before(block, page_data),
        "in_top_third": block.bbox.y_min < page_data.height * 0.33,
        "in_middle_third": ...,
        "in_bottom_third": ...,
    }
```

**í•™ìŠµ ì½”ë“œ ì˜ˆì‹œ:**
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# ë°ì´í„° ë¡œë“œ
X, y = load_training_data()

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ëª¨ë¸ í•™ìŠµ
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42
)
model.fit(X_train, y_train)

# í‰ê°€
y_pred = model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print(f"F1-Score: {f1_score(y_test, y_pred):.2f}")

# íŠ¹ì§• ì¤‘ìš”ë„
importances = model.feature_importances_
for feat, imp in zip(feature_names, importances):
    print(f"{feat}: {imp:.3f}")
```

**ì˜ˆìƒ ì„±ëŠ¥:**
- Precision: ~80-85%
- Recall: ~75-80%
- F1-Score: ~78-82%

---

### Approach 3: ë”¥ëŸ¬ë‹ (DL)

**ëª¨ë¸ í›„ë³´:**

#### 1. LSTM / GRU (ìˆœì°¨ ëª¨ë¸)
```python
import torch
import torch.nn as nn

class BlockSequenceModel(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, 2)  # binary: is_group_start

    def forward(self, x):
        # x: (batch, sequence_length, input_dim)
        lstm_out, _ = self.lstm(x)
        logits = self.fc(lstm_out)
        return logits
```

**ì¥ì :**
- ìˆœì°¨ ì •ë³´ í™œìš©
- ë¬¸ë§¥ í•™ìŠµ

**ë‹¨ì :**
- ë§ì€ í•™ìŠµ ë°ì´í„° í•„ìš”
- í•™ìŠµ ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼

#### 2. Vision Transformer (ì´ë¯¸ì§€ ê¸°ë°˜)
```python
from transformers import ViTForImageClassification

# í˜ì´ì§€ ì´ë¯¸ì§€ + ë¸”ë¡ ìœ„ì¹˜ ì •ë³´ ë™ì‹œ í•™ìŠµ
model = ViTForImageClassification.from_pretrained("google/vit-base-patch16-224")

# Fine-tuning
# ì…ë ¥: í˜ì´ì§€ ì´ë¯¸ì§€
# ì¶œë ¥: ê° ë¸”ë¡ì´ ê·¸ë£¹ ì‹œì‘ì¸ì§€ ì—¬ë¶€
```

**ì¥ì :**
- ì´ë¯¸ì§€ íŒ¨í„´ ì§ì ‘ í•™ìŠµ
- í…ìŠ¤íŠ¸ ë‚´ìš©ë„ ê³ ë ¤ ê°€ëŠ¥

**ë‹¨ì :**
- ë§¤ìš° ë§ì€ ë°ì´í„° í•„ìš”
- ê³„ì‚° ë¹„ìš© ë†’ìŒ

**ì˜ˆìƒ ì„±ëŠ¥:**
- Precision: ~90-95%
- Recall: ~85-90%
- F1-Score: ~87-92%

---

## ğŸ“‹ êµ¬í˜„ ê³„íš

### Stage 1: ê·œì¹™ ê¸°ë°˜ (1-2ì£¼)
- [ ] ê°„ê²© ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- [ ] í˜ì´ì§€ë³„ threshold ìë™ ì¶”ì •
- [ ] ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ ì¸¡ì •

### Stage 2: ë°ì´í„° ìˆ˜ì§‘ (ê³„ì†)
- [ ] Phase 3ì—ì„œ ì‚¬ìš©ì ë¼ë²¨ ìˆ˜ì§‘
- [ ] ìµœì†Œ 100í˜ì´ì§€ ë¼ë²¨ë§ ëª©í‘œ
- [ ] ë°ì´í„° ê²€ì¦ ë° ì •ì œ

### Stage 3: ML ëª¨ë¸ (1-2ê°œì›”)
- [ ] íŠ¹ì§• ì¶”ì¶œ íŒŒì´í”„ë¼ì¸
- [ ] Random Forest í•™ìŠµ
- [ ] XGBoost í•™ìŠµ
- [ ] ì„±ëŠ¥ ë¹„êµ ë° ì„ íƒ

### Stage 4: ë”¥ëŸ¬ë‹ (ì¥ê¸°, 3-6ê°œì›”)
- [ ] LSTM ëª¨ë¸ êµ¬í˜„
- [ ] Vision Transformer ì‹¤í—˜
- [ ] ì•™ìƒë¸” ëª¨ë¸

### Stage 5: í†µí•© ë° ë°°í¬
- [ ] GUIì— "ìë™ ê·¸ë£¹í•‘" ë²„íŠ¼ ì¶”ê°€
- [ ] ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡
- [ ] ì‚¬ìš©ì ìˆ˜ì • â†’ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸

---

## ğŸ¯ ì„±ê³µ ì§€í‘œ

### ì •ëŸ‰ì  ì§€í‘œ
- **Precision:** ì˜ˆì¸¡í•œ ê·¸ë£¹ì˜ ì •í™•ë„
- **Recall:** ì‹¤ì œ ê·¸ë£¹ì„ ì–¼ë§ˆë‚˜ ì°¾ì•˜ëŠ”ê°€
- **F1-Score:** Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· 

**ëª©í‘œ:**
- ê·œì¹™ ê¸°ë°˜: F1 â‰¥ 65%
- ML ê¸°ë°˜: F1 â‰¥ 80%
- DL ê¸°ë°˜: F1 â‰¥ 90%

### ì •ì„±ì  ì§€í‘œ
- ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼ í•˜ëŠ” ê·¸ë£¹ ë¹„ìœ¨ < 20%
- í‰ê·  ìˆ˜ì • ì‹œê°„ < 30ì´ˆ/í˜ì´ì§€

---

## ğŸ’¾ ë°ì´í„° ê´€ë¦¬

### í•™ìŠµ ë°ì´í„° ì €ì¥
```
dataset_root/
â””â”€â”€ ml_training/
    â”œâ”€â”€ features/              # ì¶”ì¶œëœ íŠ¹ì§•
    â”‚   â””â”€â”€ {doc_id}_page_{num}.json
    â”œâ”€â”€ labels/                # ë¼ë²¨ (Phase 3 ê²°ê³¼)
    â”‚   â””â”€â”€ {doc_id}_page_{num}_labels.json
    â”œâ”€â”€ splits/                # í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• 
    â”‚   â”œâ”€â”€ train.txt
    â”‚   â”œâ”€â”€ val.txt
    â”‚   â””â”€â”€ test.txt
    â””â”€â”€ models/                # í•™ìŠµëœ ëª¨ë¸
        â”œâ”€â”€ baseline_v1.pkl
        â”œâ”€â”€ rf_v1.pkl
        â””â”€â”€ xgb_v1.pkl
```

---

## ğŸ”„ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸

**ì›Œí¬í”Œë¡œìš°:**
```
1. ì‚¬ìš©ìê°€ ìë™ ê·¸ë£¹í•‘ ê²°ê³¼ ìˆ˜ì •
   â†“
2. ìˆ˜ì • ì‚¬í•­ ê¸°ë¡
   â†“
3. Nê°œ ì´ìƒ ìˆ˜ì • ëˆ„ì  ì‹œ
   â†“
4. ìë™ìœ¼ë¡œ ì¬í•™ìŠµ íŠ¸ë¦¬ê±°
   â†“
5. ìƒˆ ëª¨ë¸ ê²€ì¦
   â†“
6. ì„±ëŠ¥ ê°œì„ ë˜ë©´ ë°°í¬
   â†“
7. ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
```

---

## ğŸš€ ë§ˆì¼ìŠ¤í†¤

### Short-term (1-3ê°œì›”)
- [ ] ê·œì¹™ ê¸°ë°˜ êµ¬í˜„
- [ ] 100í˜ì´ì§€ ë¼ë²¨ë§
- [ ] ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ ì¸¡ì •

### Mid-term (3-6ê°œì›”)
- [ ] ML ëª¨ë¸ í•™ìŠµ
- [ ] F1-Score â‰¥ 80% ë‹¬ì„±
- [ ] GUI í†µí•©

### Long-term (6-12ê°œì›”)
- [ ] 1000í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘
- [ ] ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‹¤í—˜
- [ ] F1-Score â‰¥ 90% ë‹¬ì„±
- [ ] ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìë™í™”

---

## ğŸ“ ì—°êµ¬ ë°©í–¥

### ê°œì„  ì•„ì´ë””ì–´
1. **ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ**
   - ê·¸ë£¹ ê²½ê³„ + ë¬¸ì œ ìœ í˜• ë™ì‹œ ì˜ˆì¸¡

2. **ëŠ¥ë™ í•™ìŠµ (Active Learning)**
   - ëª¨ë¸ì´ ë¶ˆí™•ì‹¤í•œ ê²½ìš°ë§Œ ì‚¬ìš©ìì—ê²Œ ì§ˆë¬¸

3. **ì „ì´ í•™ìŠµ (Transfer Learning)**
   - ë‹¤ë¥¸ ë¬¸ì œì§‘ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµ
   - Fine-tuningìœ¼ë¡œ ë¹ ë¥¸ ì ì‘

4. **Few-shot Learning**
   - ì ì€ ë°ì´í„°ë¡œ ìƒˆë¡œìš´ ë¬¸ì„œ ìœ í˜• í•™ìŠµ

---

## âœ… Phase 4 ì™„ë£Œ ê¸°ì¤€

### ìµœì†Œ ìš”êµ¬ì‚¬í•­
- [ ] ê·œì¹™ ê¸°ë°˜ êµ¬í˜„ (F1 â‰¥ 65%)
- [ ] 100í˜ì´ì§€ ë¼ë²¨ ë°ì´í„°
- [ ] GUI í†µí•©

### ì´ìƒì  ëª©í‘œ
- [ ] ML ëª¨ë¸ (F1 â‰¥ 80%)
- [ ] 500í˜ì´ì§€ ë¼ë²¨ ë°ì´í„°
- [ ] ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸

---

**ìƒíƒœ:** ğŸ’¡ ì¥ê¸° ê³„íš
**ì´ì „ Phase:** [Phase 3: ê·¸ë£¹í•‘ ê¸°ëŠ¥](03_phase3_grouping_plan.md) ğŸ“…
**ì „ì²´ ê°œìš”:** [í”„ë¡œì íŠ¸ ê°œìš”](00_project_overview.md)
